{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DUDL_FFNmilestone_project2.ipynb",
   "provenance": [
    {
     "file_id": "1o_dLKV6fY7xdZYx_pNMY12zpL_pmMurs",
     "timestamp": 1618865813618
    },
    {
     "file_id": "1Q9LtmanyNt675-gO_kXRBKalCdP6xtvV",
     "timestamp": 1617253457100
    },
    {
     "file_id": "1jeqKEJfI18GlAhSG8RO5aJ6Vrp4-nkTt",
     "timestamp": 1615909315432
    },
    {
     "file_id": "10_geQnah5AvMsm8VDAQwNPhypOXradar",
     "timestamp": 1615893340208
    },
    {
     "file_id": "1FtQ99beHYcDFDywLdaPgFm-KjBeI8PvD",
     "timestamp": 1615877547147
    }
   ],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyOIyRMAxGJWy3GWMPnYTqHU"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: FFN milestone projects\n",
    "### LECTURE: Project 2: Predicting heart disease\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202401"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Gueyy3lJ7Jxy"
   },
   "source": [
    "# Data information:\n",
    "# https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "\n",
    "# Data source\n",
    "# https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j7-LiwqUMGYL"
   },
   "source": [
    "### import libraries\n",
    "\n",
    "# for DL modeling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for number-crunching\n",
    "import numpy as np\n",
    "\n",
    "# for dataset management\n",
    "import pandas as pd\n",
    "\n",
    "# for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2anVFzBXGdwH"
   },
   "source": [
    "# Import and process the data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0ohXIxzt4_U2"
   },
   "source": [
    "# import the data\n",
    "url  = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data'\n",
    "data = pd.read_csv(url,sep=',',header=None)\n",
    "data.columns = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','DISEASE']\n",
    "\n",
    "\n",
    "# data contain some ?'s; replace with NaN and drop those rows\n",
    "data = data.replace('?',np.nan).dropna()\n",
    "\n",
    "data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AFsS6iQPSUnM"
   },
   "source": [
    "# describe the data\n",
    "data.describe()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xuggtlf2SZtr"
   },
   "source": [
    "# check the distributions\n",
    "fig,ax = plt.subplots(1,figsize=(17,4))\n",
    "ax = sns.boxplot(data=data)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "axeKaHIKTylU"
   },
   "source": [
    "# z-score the non-categorical columns\n",
    "cols2zscore = data.keys()\n",
    "cols2zscore = cols2zscore.drop(['sex','fbs','exang','DISEASE'])\n",
    "cols2zscore\n",
    "\n",
    "for c in cols2zscore:\n",
    "  d = pd.to_numeric(data[c]) # force to numeric (addresses some data-format issues)\n",
    "  data[c] = (d - d.mean())/d.std(ddof=1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "21FezJ0XT7pp"
   },
   "source": [
    "# check the distributions again\n",
    "fig,ax = plt.subplots(1,figsize=(17,4))\n",
    "ax = sns.boxplot(data=data)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7TW5me0MTVc5"
   },
   "source": [
    "# count of all unique types of 'DISEASE'\n",
    "data['DISEASE'].value_counts()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nbCconDLTcw8"
   },
   "source": [
    "# re-code events to 0 (absent) and 1 (present)\n",
    "data['DISEASE'][data['DISEASE']>0] = 1"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGQd7xmM5Gns"
   },
   "source": [
    "# Re-organize the data: train/test in DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2kZ6YPe8Gav5"
   },
   "source": [
    "# convert from pandas dataframe to tensor\n",
    "dataT  = torch.tensor( data[data.keys().drop('DISEASE')].values ).float()\n",
    "labels = torch.tensor( data['DISEASE'].values ).float()\n",
    "\n",
    "print( dataT.shape )\n",
    "print( labels.shape )\n",
    "\n",
    "# we'll actually need the labels to be a \"matrix\"\n",
    "labels = labels[:,None]\n",
    "print( labels.shape )"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FxZlcwRwKtBl"
   },
   "source": [
    "# use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labels, test_size=50)\n",
    "\n",
    "# then convert them into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# finally, translate into dataloader objects\n",
    "batchsize    = 20\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bbf064xxGa_x"
   },
   "source": [
    "# check sizes of data batches\n",
    "for X,y in train_loader:\n",
    "  print(X.shape,  y.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VToReEHNWP0n"
   },
   "source": [
    "# Create a class for the DL model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RVcrKOC1Wqk-"
   },
   "source": [
    "# the class\n",
    "class theNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    ### input layer\n",
    "    self.input = nn.Linear(13,32)\n",
    "    \n",
    "    ### hidden layers\n",
    "    self.fc1 = nn.Linear(32,64)\n",
    "    self.fc2 = nn.Linear(64,10)\n",
    "\n",
    "    ### output layer\n",
    "    self.output = nn.Linear(10,1)\n",
    "  \n",
    "  # forward pass\n",
    "  def forward(self,x):\n",
    "    x = F.relu( self.input(x) )\n",
    "    x = F.relu( self.fc1(x) )\n",
    "    x = F.relu( self.fc2(x) )\n",
    "    return self.output(x)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zQKkLPUeWqn_"
   },
   "source": [
    "# test the model on a bit of data\n",
    "net = theNet()\n",
    "\n",
    "X,y = next(iter(train_loader))\n",
    "yHat = net(X)\n",
    "print(yHat)\n",
    "\n",
    "# test the loss function\n",
    "lossfun = nn.BCEWithLogitsLoss()\n",
    "lossfun(yHat,y)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUMPfhoFWqrA"
   },
   "source": [
    "# Train the model and show performance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4aUKZKn5Wqt-"
   },
   "source": [
    "# start with a fresh network\n",
    "net = theNet()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=.0001)\n",
    "lossfun = nn.BCEWithLogitsLoss() # try with different loss function\n",
    "\n",
    "\n",
    "# number of training epochs\n",
    "numepochs = 100\n",
    "\n",
    "\n",
    "# initialize losses and accuracies\n",
    "trainLoss = torch.zeros(numepochs)\n",
    "testLoss  = torch.zeros(numepochs)\n",
    "trainAcc  = torch.zeros(numepochs)\n",
    "testAcc   = torch.zeros(numepochs)\n",
    "\n",
    "\n",
    "# loop over epochs\n",
    "for epochi in range(numepochs):\n",
    "\n",
    "  # loop over training data batches\n",
    "  batchLoss = []\n",
    "  for X,y in train_loader:\n",
    "\n",
    "    # forward pass and loss\n",
    "    yHat = net(X)\n",
    "    loss = lossfun(yHat,y)\n",
    "\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # loss from this batch\n",
    "    batchLoss.append(loss.item())\n",
    "    \n",
    "    # train accuracy\n",
    "    predictions = (torch.sigmoid(yHat)>.5).float()\n",
    "    trainAcc[epochi] = 100*torch.mean((predictions==y).float())\n",
    "\n",
    "  # end of batch loop...\n",
    "\n",
    "  # get average losses across the batches\n",
    "  trainLoss[epochi] = np.mean(batchLoss)\n",
    "\n",
    "\n",
    "  ## now for the test\n",
    "  X,y = next(iter(test_loader))\n",
    "  yHat = net(X)\n",
    "  \n",
    "  # test loss\n",
    "  loss = lossfun(yHat,y)\n",
    "  testLoss[epochi] = loss.item()\n",
    "  \n",
    "  # test accuracy\n",
    "  predictions = (torch.sigmoid(yHat)>.5).float()\n",
    "  testAcc[epochi] = 100*torch.mean((predictions==y).float())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V_Au7fIUWq0H"
   },
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(16,5))\n",
    "\n",
    "ax[0].plot(trainLoss,'s-',label='Train')\n",
    "ax[0].plot(testLoss,'s-',label='Test')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_title('Model loss')\n",
    "\n",
    "ax[1].plot(trainAcc,'s-',label='Train')\n",
    "ax[1].plot(testAcc,'o-',label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy (%)')\n",
    "ax[1].set_title(f'Final model test accuracy: {testAcc[-1]:.2f}%')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TB4GbxkSWrK-"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}