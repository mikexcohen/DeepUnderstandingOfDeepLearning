{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DUDL_convolution_conv2transpose.ipynb",
   "provenance": [
    {
     "file_id": "19imE5cZVTySOpFOe4Uvw97qMPMgs0MJ2",
     "timestamp": 1620678031999
    },
    {
     "file_id": "1GRajDS-VF5z8IslzZuMqbis3X6HDD-Uo",
     "timestamp": 1619468278654
    },
    {
     "file_id": "1m0n2-UmB2tJiIDadlFkE6L5A4iZSqeBf",
     "timestamp": 1619459134813
    },
    {
     "file_id": "19G9gTeBlYPQ-s3VS_3K2bVFtKTP344j6",
     "timestamp": 1619444797767
    },
    {
     "file_id": "1FcEBC0NAESIlHQkv6_85R-XDUKGE8XbM",
     "timestamp": 1619155961717
    },
    {
     "file_id": "1qKgZ8kVcqNgwtBzHbWq5yJH_HqI6DxWW",
     "timestamp": 1617803880910
    },
    {
     "file_id": "15cpyHkJ435B4MqbyGjAH1poN4nCy_DE4",
     "timestamp": 1617737766196
    },
    {
     "file_id": "1OLuWuaFu0hcFgkQ2hh5BqbRuqUZD7XcQ",
     "timestamp": 1617734878578
    },
    {
     "file_id": "1XvzVGJPTJifVh8OpZVB7ykLxyUqYwQ1j",
     "timestamp": 1617196833019
    },
    {
     "file_id": "1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H",
     "timestamp": 1617124341706
    },
    {
     "file_id": "1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn",
     "timestamp": 1616697516760
    },
    {
     "file_id": "1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg",
     "timestamp": 1616615469755
    },
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1616608248670
    }
   ],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyMmwDcfzKJX666dqNPAElf7"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Image convolution and transformations\n",
    "### LECTURE: Transpose convolution\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202401"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YeuAheYyhdZw"
   },
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HOkOefftqyg"
   },
   "source": [
    "# Create a transpose convolution instance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VhIKo0_iaGz2"
   },
   "source": [
    "# create a ConvTranspose2d class instance with parameters\n",
    "\n",
    "# parameters\n",
    "inChans  = 3 # RGB\n",
    "outChans = 15\n",
    "krnSize  = 5 # should be an odd number\n",
    "stride   = 1\n",
    "padding  = 0\n",
    "\n",
    "# create the instance\n",
    "c = nn.ConvTranspose2d(inChans,outChans,krnSize,stride,padding)\n",
    "\n",
    "# let's have a look at it\n",
    "print(c)\n",
    "print(' ')\n",
    "\n",
    "# check out its weight tensor; what are the dimensions?\n",
    "print( 'Size of weights: ' + str(c.weight.shape) )\n",
    "print( 'Size of bias: ' + str(c.bias.shape) )\n",
    "\n",
    "# tip: Compare the sizes of these weights with those of \"forward\" convolution (DUDL_convolution_conv2.ipynb)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N6p50RaP4kce"
   },
   "source": [
    "# What do these kernels look like?\n",
    "\n",
    "fig,axs = plt.subplots(3,5,figsize=(10,5))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "  ax.imshow(torch.squeeze(c.weight[0,i,:,:]).detach(),cmap='Purples')\n",
    "  ax.set_title('L1(0)->L2(%s)'%i)\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAqVrcrGd98S"
   },
   "source": [
    "# Convolve with an image"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9SnUUHPm7xQE"
   },
   "source": [
    "# size of the image (N, RGB, width, height)\n",
    "imsize = (1,3,64,64)\n",
    "\n",
    "img = torch.rand(imsize)\n",
    "\n",
    "# pytorch wants channels first, but matplotlib wants channels last.\n",
    "# therefore, tensors must be permuted to visualize\n",
    "img2view = img.permute(2,3,1,0).numpy()\n",
    "print(img.shape)\n",
    "print(img2view.shape)\n",
    "\n",
    "plt.imshow(np.squeeze(img2view));"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2WcTRmLu4F23"
   },
   "source": [
    "# convolve the image with the filter bank (set of 'outChans' kernels)\n",
    "convRes = c(img)\n",
    "\n",
    "print(img.shape)\n",
    "print(convRes.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "poDa9N6TwjPu"
   },
   "source": [
    "# What do the convolved images look like? (Hint: think of the bathtub picture.)\n",
    "\n",
    "fig,axs = plt.subplots(3,5,figsize=(10,5))\n",
    "\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "\n",
    "  # extract this \"layer\" of the convolution result\n",
    "  I = torch.squeeze(convRes[0,i,:,:]).detach()\n",
    "\n",
    "  # and visualize it\n",
    "  ax.imshow(I,cmap='Purples')\n",
    "  ax.set_title('Conv. w/ filter %s'%i)\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fCooGt9PiNb6"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}