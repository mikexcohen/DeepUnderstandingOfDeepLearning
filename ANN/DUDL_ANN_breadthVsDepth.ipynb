{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1V0mkFVCMTAd0iq30FIpXspezzE7PpVrX",
     "timestamp": 1616523401452
    },
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1615925514977
    }
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: ANNs\n",
    "### LECTURE: Model depth vs. breadth\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202401"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YeuAheYyhdZw"
   },
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ViJutqaaNb2"
   },
   "source": [
    "# Import and organize the data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MU7rvmWuhjud"
   },
   "source": [
    "# import dataset\n",
    "import pandas as pd\n",
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "\n",
    "# convert from pandas dataframe to tensor\n",
    "data = torch.tensor( iris[iris.columns[0:4]].values ).float()\n",
    "\n",
    "# transform species to number\n",
    "labels = torch.zeros(len(data), dtype=torch.long)\n",
    "# labels[iris.species=='setosa'] = 0 # don't need!\n",
    "labels[iris.species=='versicolor'] = 1\n",
    "labels[iris.species=='virginica'] = 2"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCuMSE6baRar"
   },
   "source": [
    "# Construct and sanity-check the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eZMzMLxfULjf"
   },
   "source": [
    "# create a class for the model\n",
    "\n",
    "class ANNiris(nn.Module):\n",
    "  def __init__(self,nUnits,nLayers):\n",
    "    super().__init__()\n",
    "\n",
    "    # create dictionary to store the layers\n",
    "    self.layers = nn.ModuleDict()\n",
    "    self.nLayers = nUnits#nLayers#\n",
    "\n",
    "    ### input layer\n",
    "    self.layers['input'] = nn.Linear(4,nUnits)\n",
    "\n",
    "    ### hidden layers\n",
    "    for i in range(nLayers):\n",
    "      self.layers[f'hidden{i}'] = nn.Linear(nUnits,nUnits)\n",
    "\n",
    "    ### output layer\n",
    "    self.layers['output'] = nn.Linear(nUnits,3)\n",
    "\n",
    "\n",
    "  # forward pass\n",
    "  def forward(self,x):\n",
    "    # input layer (note: the code in the video omits the relu after this layer)\n",
    "    x = F.relu( self.layers['input'](x) )\n",
    "\n",
    "    # hidden layers\n",
    "    for i in range(self.nLayers):\n",
    "      x = F.relu( self.layers[f'hidden{i}'](x) )\n",
    "\n",
    "    # return output layer\n",
    "    x = self.layers['output'](x)\n",
    "    return x"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2-GmvNgEYgHK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1676840556776,
     "user_tz": -540,
     "elapsed": 7,
     "user": {
      "displayName": "Mike X Cohen",
      "userId": "13901636194183843661"
     }
    },
    "outputId": "64aaf42f-9ea9-4c3f-d621-40ede6bdc0d9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# generate an instance of the model and inspect it\n",
    "nUnitsPerLayer = 12\n",
    "nLayers = 4\n",
    "net = ANNiris(nUnitsPerLayer,nLayers)\n",
    "net"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ANNiris(\n",
       "  (layers): ModuleDict(\n",
       "    (input): Linear(in_features=4, out_features=12, bias=True)\n",
       "    (hidden0): Linear(in_features=12, out_features=12, bias=True)\n",
       "    (hidden1): Linear(in_features=12, out_features=12, bias=True)\n",
       "    (hidden2): Linear(in_features=12, out_features=12, bias=True)\n",
       "    (hidden3): Linear(in_features=12, out_features=12, bias=True)\n",
       "    (output): Linear(in_features=12, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XwtrXLSNYyC8",
    "executionInfo": {
     "status": "error",
     "timestamp": 1676840557650,
     "user_tz": -540,
     "elapsed": 878,
     "user": {
      "displayName": "Mike X Cohen",
      "userId": "13901636194183843661"
     }
    },
    "outputId": "61867ff5-2e94-4f91-ec8c-cde7008638fd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    }
   },
   "source": [
    "# A quick test of running some numbers through the model.\n",
    "# This simply ensures that the architecture is internally consistent.\n",
    "\n",
    "\n",
    "# 10 samples, 4 dimensions\n",
    "tmpx = torch.randn(10,4)\n",
    "\n",
    "# run it through the DL\n",
    "y = net(tmpx)\n",
    "\n",
    "# exam the shape of the output\n",
    "print( y.shape ), print(' ')\n",
    "\n",
    "# and the output itself\n",
    "print(y)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3fb37aeb8270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# run it through the DL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# exam the shape of the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-814c6ca3b987>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# hidden layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnLayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'hidden{i}'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# return output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_copy_to_script_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'hidden4'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YL7cvyjUaXjc"
   },
   "source": [
    "# Create a function that trains the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cVD1nFTli7TO"
   },
   "source": [
    "# a function to train the model\n",
    "\n",
    "def trainTheModel(theModel):\n",
    "\n",
    "  # define the loss function and optimizer\n",
    "  lossfun = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.SGD(theModel.parameters(),lr=.01)\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # forward pass\n",
    "    yHat = theModel(data)\n",
    "\n",
    "    # compute loss\n",
    "    loss = lossfun(yHat,labels)\n",
    "\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "  # final forward pass to get accuracy\n",
    "  predictions = theModel(data)\n",
    "  predlabels = torch.argmax(predictions,axis=1)\n",
    "  acc = 100*torch.mean((predlabels == labels).float())\n",
    "\n",
    "  # total number of trainable parameters in the model\n",
    "  nParams = sum(p.numel() for p in theModel.parameters() if p.requires_grad)\n",
    "\n",
    "  # function outputs\n",
    "  return acc,nParams"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "41R4X0MCaxVc"
   },
   "source": [
    "# test the function once\n",
    "\n",
    "numepochs = 2500\n",
    "acc = trainTheModel(net)\n",
    "\n",
    "# check the outputs\n",
    "acc # tuple containing (accuracy,nparams)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lE1lhk5356g7"
   },
   "source": [
    "# Now for the experiment!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hWOzwwHTrdxz"
   },
   "source": [
    "# this cell takes ~2 mins\n",
    "\n",
    "# define the model parameters\n",
    "numlayers = range(1,6)         # number of hidden layers\n",
    "numunits  = np.arange(4,101,3) # units per hidden layer\n",
    "\n",
    "# initialize output matrices\n",
    "accuracies  = np.zeros((len(numunits),len(numlayers)))\n",
    "totalparams = np.zeros((len(numunits),len(numlayers)))\n",
    "\n",
    "# number of training epochs\n",
    "numepochs = 500\n",
    "\n",
    "\n",
    "# start the experiment!\n",
    "for unitidx in range(len(numunits)):\n",
    "  for layeridx in range(len(numlayers)):\n",
    "\n",
    "    # create a fresh model instance\n",
    "    net = ANNiris(numunits[unitidx],numlayers[layeridx])\n",
    "\n",
    "    # run the model and store the results\n",
    "    acc,nParams = trainTheModel(net)\n",
    "    accuracies[unitidx,layeridx] = acc\n",
    "\n",
    "    # store the total number of parameters in the model\n",
    "    totalparams[unitidx,layeridx] = nParams\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JYouZAY4i3jM"
   },
   "source": [
    "# show accuracy as a function of model depth\n",
    "fig,ax = plt.subplots(1,figsize=(12,6))\n",
    "\n",
    "ax.plot(numunits,accuracies,'o-',markerfacecolor='w',markersize=9)\n",
    "ax.plot(numunits[[0,-1]],[33,33],'--',color=[.8,.8,.8])\n",
    "ax.plot(numunits[[0,-1]],[67,67],'--',color=[.8,.8,.8])\n",
    "ax.legend(numlayers)\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_xlabel('Number of hidden units')\n",
    "ax.set_title('Accuracy')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "St6NI4qBk4tO"
   },
   "source": [
    "# Maybe it's simply a matter of more parameters -> better performance?\n",
    "\n",
    "# vectorize for convenience\n",
    "x = totalparams.flatten()\n",
    "y = accuracies.flatten()\n",
    "\n",
    "# correlation between them\n",
    "r = np.corrcoef(x,y)[0,1]\n",
    "\n",
    "# scatter plot\n",
    "plt.plot(x,y,'o')\n",
    "plt.xlabel('Number of parameters')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Correlation: r=' + str(np.round(r,3)))\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3ix4I-SgJzXX"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmraVzTcJ0x1"
   },
   "source": [
    "# Additional explorations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pml6nCTcAMWC"
   },
   "source": [
    "# 1) Try it again with 1000 training epochs. Do the deeper models eventually learn?\n",
    "#\n",
    "# 2) The categories are coded a \"0\", \"1\", and \"2\". Is there something special about those numbers?\n",
    "#    Recode the labels to be, e.g., 5, 10, and 17. Or perhaps -2, 0, and 2. Is the model still able to learn?\n",
    "#"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}