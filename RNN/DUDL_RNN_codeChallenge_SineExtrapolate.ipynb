{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4231a7fe",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ydebessu/DeepUnderstandingOfDeepLearning/blob/main/RNN/DUDL_RNN_codeChallenge_SineExtrapolate.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: RNNs (and LSTM and GRU)\n",
    "### LECTURE: CodeChallenge: Sine wave extrapolation\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7-LiwqUMGYL"
   },
   "outputs": [],
   "source": [
    "### import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# for printing out status reports\n",
    "import sys\n",
    "\n",
    "# for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2anVFzBXGdwH"
   },
   "source": [
    "# Create temporal sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ohXIxzt4_U2"
   },
   "outputs": [],
   "source": [
    "# import the data\n",
    "N = 500\n",
    "\n",
    "time = torch.linspace(0,30*np.pi,N)\n",
    "data = torch.sin(time+torch.cos(time))\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.plot(data,'ks-',markerfacecolor='w')\n",
    "plt.xlim([-5,N+4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VToReEHNWP0n"
   },
   "source": [
    "# Create a class for the DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVcrKOC1Wqk-"
   },
   "outputs": [],
   "source": [
    "class rnnnet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    # RNN Layer\n",
    "    self.rnn = nn.RNN(input_size,num_hidden,num_layers)\n",
    "    \n",
    "    # linear layer for output\n",
    "    self.out = nn.Linear(num_hidden,1)\n",
    "  \n",
    "  def forward(self, x, h):\n",
    "    \n",
    "    # run through the RNN layer\n",
    "    y,hidden = self.rnn(x,h)\n",
    "    \n",
    "    # and the output (linear) layer\n",
    "    y = self.out(y)\n",
    "    \n",
    "    return y,hidden.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQKkLPUeWqn_"
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_size =  1 # \"channels\" of data\n",
    "num_hidden =  9 # breadth of model (number of units in hidden layers)\n",
    "num_layers =  1 # depth of model (number of \"stacks\" of hidden layers)\n",
    "seqlength  = 30 # number of datapoints used for learning in each segment\n",
    "batchsize  =  1 # Note: the training code is actually hard-coded to organize data into batchsize=1\n",
    "\n",
    "# create an instance of the model and inspect\n",
    "net = rnnnet()\n",
    "\n",
    "X = torch.rand(seqlength,batchsize,input_size)\n",
    "y,h = net(X,None) # None is for empty hidden state input\n",
    "print(X.shape)\n",
    "print(y.shape) # note: one output per sequence element; generally, we take the final output to force a \"many-to-one\" design.\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rn9PgvVXcQuz"
   },
   "outputs": [],
   "source": [
    "# is it enough data?\n",
    "\n",
    "plt.plot(data[:seqlength],'ks-',markerfacecolor='w')\n",
    "plt.title(f'First {seqlength} data points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WL8wjwn0Jwr"
   },
   "outputs": [],
   "source": [
    "# test the model with some data\n",
    "somedata = data[:seqlength].view(seqlength,1,1)\n",
    "y = net(somedata,None)\n",
    "\n",
    "# grab the final predicted value from the output (first element of tuple output of net)\n",
    "finalValue = y[0][-1]\n",
    "\n",
    "lossfun = nn.MSELoss()\n",
    "lossfun(finalValue,data[seqlength].view(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUMPfhoFWqrA"
   },
   "source": [
    "# Train the model and show performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4aUKZKn5Wqt-"
   },
   "outputs": [],
   "source": [
    "# number of training epochs\n",
    "numepochs = 30\n",
    "\n",
    "# create a new instance of the model (and optimizer!)\n",
    "net = rnnnet()\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=.001)\n",
    "\n",
    "\n",
    "\n",
    "# initialize losses\n",
    "losses = np.zeros(numepochs)\n",
    "signaccuracy = np.zeros(numepochs)\n",
    "\n",
    "# loop over epochs\n",
    "for epochi in range(numepochs):\n",
    "\n",
    "  # loop over data segments\n",
    "  seglosses = []\n",
    "  segacc    = []\n",
    "  hiddenstate = None\n",
    "\n",
    "  for timei in range(N-seqlength):\n",
    "\n",
    "    # grab a snippet of data\n",
    "    X = data[timei:timei+seqlength].view(seqlength,1,1)\n",
    "    y = data[timei+seqlength].view(1,1)\n",
    "\n",
    "    # forward pass and loss\n",
    "    yHat,hiddenstate = net(X,hiddenstate)\n",
    "    finalValue = yHat[-1]\n",
    "    loss = lossfun(finalValue,y) # compare final value of output\n",
    "\n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # loss from this segment\n",
    "    seglosses.append(loss.item())\n",
    "  \n",
    "  # average losses from this epoch\n",
    "  losses[epochi] = np.mean(seglosses)\n",
    "  \n",
    "  msg = f'Finished epoch {epochi+1}/{numepochs}'\n",
    "  sys.stdout.write('\\r' + msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_Au7fIUWq0H"
   },
   "outputs": [],
   "source": [
    "## let's see how the model did!\n",
    "\n",
    "plt.plot(losses,'s-')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TB4GbxkSWrK-"
   },
   "outputs": [],
   "source": [
    "# now test the network!\n",
    "\n",
    "h = np.zeros((N,num_hidden))\n",
    "\n",
    "yHat = np.zeros(N)\n",
    "hh = None\n",
    "for timei in range(N-seqlength):\n",
    "\n",
    "  # grab a snippet of data\n",
    "  X = data[timei:timei+seqlength].view(seqlength,1,1)\n",
    "\n",
    "  # forward pass and loss\n",
    "  yy,hh = net(X,hh)\n",
    "  yHat[timei+seqlength] = yy[-1]\n",
    "  h[timei+seqlength,:] = hh.detach()\n",
    "\n",
    "\n",
    "## plot!\n",
    "fig,ax = plt.subplots(1,3,figsize=(16,4))\n",
    "ax[0].plot(data,'bs-',label='Actual data',markersize=3)\n",
    "ax[0].plot(yHat,'ro-',label='Predicted',markersize=3)\n",
    "ax[0].set_ylim([-1.1,1.1])\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(data-yHat,'k^')\n",
    "ax[1].set_ylim([-1.1,1.1])\n",
    "ax[1].set_title('Errors')\n",
    "\n",
    "ax[2].plot(data[seqlength:],yHat[seqlength:],'mo',markersize=3)\n",
    "ax[2].set_xlabel('Real data')\n",
    "ax[2].set_ylabel('Predicted data')\n",
    "r = np.corrcoef(data[seqlength:],yHat[seqlength:])\n",
    "ax[2].set_title(f\"r={r[0,1]:.2f} (NO Simpson's paradox!)\")\n",
    "\n",
    "plt.suptitle('Performance on training data',fontweight='bold',fontsize=20,y=1.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rE0uHldnpoar"
   },
   "outputs": [],
   "source": [
    "# show the hidden \"states\" (units activations)\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "plt.plot(h,'s-',markersize=3)\n",
    "plt.xlabel('Sequence index')\n",
    "plt.ylabel('State value (a.u.)')\n",
    "plt.title('Each line is a different hidden unit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9x4fwIJ_7M0"
   },
   "outputs": [],
   "source": [
    "# plot the weights for the input->hidden layers\n",
    "plt.bar(range(num_hidden),net.rnn.weight_ih_l0.detach())\n",
    "plt.ylabel('Weight value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YukkwGPXNxvn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLH6POAU_5sy"
   },
   "source": [
    "# Test with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MYMSUJq6_7J1"
   },
   "outputs": [],
   "source": [
    "## Create new data (orange case: different frequency)\n",
    "time = torch.linspace(0,10*np.pi,N)\n",
    "newdata = torch.sin(time+torch.cos(time))\n",
    "\n",
    "# Create new data (red case: different function)\n",
    "time = torch.linspace(0,30*np.pi,N)\n",
    "newdata = torch.sin(time+torch.sin(time))\n",
    "\n",
    "\n",
    "\n",
    "# loop over time and predict each subsequent value\n",
    "yHat = np.zeros(N)\n",
    "h = None\n",
    "for timei in range(N-seqlength):\n",
    "\n",
    "  # grab a snippet of data\n",
    "  X = newdata[timei:timei+seqlength].view(seqlength,1,1)\n",
    "\n",
    "  # forward pass and loss (don't need hidden states here)\n",
    "  yy,h = net(X,h)\n",
    "  yHat[timei+seqlength] = yy[-1]\n",
    "\n",
    "\n",
    "# plotting\n",
    "fig,ax = plt.subplots(1,3,figsize=(16,4))\n",
    "ax[0].plot(newdata,'bs-',label='Actual data',markersize=3)\n",
    "ax[0].plot(yHat,'ro-',label='Predicted',markersize=3)\n",
    "ax[0].set_ylim([-1.1,1.1])\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(newdata-yHat,'k^',markersize=3)\n",
    "ax[1].set_ylim([-1.1,1.1])\n",
    "ax[1].set_title('Errors')\n",
    "\n",
    "ax[2].plot(newdata[seqlength:],yHat[seqlength:],'mo',markersize=3)\n",
    "ax[2].set_xlabel('Real data')\n",
    "ax[2].set_ylabel('Predicted data')\n",
    "r = np.corrcoef(newdata[seqlength:],yHat[seqlength:])\n",
    "ax[2].set_title(f\"r={r[0,1]:.2f}\")\n",
    "\n",
    "plt.suptitle('Performance on unseen test data',fontweight='bold',fontsize=20,y=1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrjFcvpU3Fwz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyXV09x74R7B"
   },
   "source": [
    "# Longer-term extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9nsmFPZ3ShE"
   },
   "outputs": [],
   "source": [
    "# using original data\n",
    "\n",
    "# create a signal 2x as long\n",
    "yHat = torch.zeros(2*N) # torch, not np!\n",
    "yHat[:N] = data\n",
    "h = None\n",
    "\n",
    "for timei in range(2*N-seqlength):\n",
    "\n",
    "  # grab a snippet of data\n",
    "  X = yHat[timei:timei+seqlength].view(seqlength,1,1)\n",
    "  \n",
    "  # forward pass and loss\n",
    "  yy,h = net(X,h)\n",
    "  yHat[timei+seqlength] = yy[-1]\n",
    "\n",
    "\n",
    "\n",
    "# convert back to np for plotting\n",
    "yHat = yHat.detach()\n",
    "\n",
    "# plotting\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "plt.plot(data,'bs-',label='Actual data',markersize=3)\n",
    "plt.plot(yHat,'ro-',label='Predicted',markersize=3)\n",
    "plt.ylim([-1.1,1.1])\n",
    "plt.legend()\n",
    "plt.title('Performance on extrapolated data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXtU8uw-_7P0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdQ9d5UC_7Ss"
   },
   "source": [
    "# Additional explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9EweIKOI1td"
   },
   "outputs": [],
   "source": [
    "# 1) Extrapolation was awful! Maybe the model is too simple? Try increasing the sequence length and the number\n",
    "#    of hidden units. Does that help the extrapolation?\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7ioUURaI1zN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM67vvIiExwMjkHX+cFqSsm",
   "collapsed_sections": [],
   "name": "DUDL_RNN_codeChallenge_SineExtrapolate.ipynb",
   "provenance": [
    {
     "file_id": "1fHi3muBZCv5CxetZqOzIPGCy0i0C4JHM",
     "timestamp": 1634751329854
    },
    {
     "file_id": "19WUFNKOHKnZ1hEkR6havrl_eIE4BxuaE",
     "timestamp": 1621268036592
    },
    {
     "file_id": "1BI9p-vnVoi7Tm8yiQgVN3kpM2VuEzfeE",
     "timestamp": 1621245811372
    },
    {
     "file_id": "1o_dLKV6fY7xdZYx_pNMY12zpL_pmMurs",
     "timestamp": 1618865813618
    },
    {
     "file_id": "1Q9LtmanyNt675-gO_kXRBKalCdP6xtvV",
     "timestamp": 1617253457100
    },
    {
     "file_id": "1jeqKEJfI18GlAhSG8RO5aJ6Vrp4-nkTt",
     "timestamp": 1615909315432
    },
    {
     "file_id": "10_geQnah5AvMsm8VDAQwNPhypOXradar",
     "timestamp": 1615893340208
    },
    {
     "file_id": "1FtQ99beHYcDFDywLdaPgFm-KjBeI8PvD",
     "timestamp": 1615877547147
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
